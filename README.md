---
title: "Live Electronics"
subtitle: "Un racconto plurale."
author: "Giulio Romano De Mattia"
date: "15/03/2026"
conservatorio: "Conservatorio A. Casella, L'Aquila"
corso: "Musica Elettronica DCSL34"
esame: "Storia della musica elettrocustica e Storia delle tecnologie elettroacustiche"
abstract: |
  questo dovrebbe essere il sommario...
header-includes:
  - \usepackage{styles/tesina}
documentclass: article
fontsize: 12pt
toc: true
toc-depth: 2
bibliography:
  bib: docs/bibliografia.bib
  sit: docs/sitografia.bib
csl: styles/consAq-author-date.csl
nocite: "@*"
---

# INTRODUZIONE
## Presentazione tema e domanda centrale
## Metodologia: analisi fonti primarie
## Struttura della tesi


# GENESI DEL LIVE ELECTRONICS

## "Live" vs "Real-time" - Una distinzione necessaria

Prima di approfondire l'analisi delle opere fondamentali che vanno a corroborare la tesi, è essenziale chiarire una distinzione terminologica che percorrerà l'intera ricerca. I termini *live* e *real-time*, sebbene spesso utilizzati come sinonimi, designano dimensioni profondamente differenti della pratica musicale elettroacustica.

Nella letteratura sulla computer music degli anni Settanta si afferma una tendenza problematica: l'uso del termine "tempo reale" (*real-time*) per descrivere pratiche performative. Come rileva Di Scipio, le istituzioni di computer music hanno costantemente parlato di "computer in tempo reale" piuttosto che di "live electronics", privilegiando "the technologically-determined criterion of higher and higher computational speed in the description of performative resources" [@discipio2021thinking, 177].

Questa scelta terminologica rivela un equivoco concettuale che merita chiarimento. La categoria di *real-time* appartiene al dominio dell'informatica e designa una proprietà specifica dei sistemi computazionali: la capacità di processare dati con latenze sufficientemente ridotte da risultare impercettibili all'orecchio umano. Si tratta di una caratteristica tecnica quantificabile, legata alla velocità dei processori e all'efficienza degli algoritmi — dunque, essenzialmente, una questione di ingegneria informatica.

La dimensione del "dal vivo" (*live*) riguarda invece un ordine di fenomeni completamente differente. Il live electronics non si definisce attraverso parametri di latenza computazionale, ma attraverso le condizioni dell'evento performativo: la generazione e manipolazione dei suoni avviene contestualmente all'atto esecutivo, attraverso l'azione diretta di performer su dispositivi elettroacustici, in presenza di un pubblico, all'interno di uno spazio fisico determinato. 

Di Scipio sottolinea che questa distinzione non rappresenta un mero tecnicismo linguistico, ma possiede implicazioni epistemologiche profonde. La nozione di *real-time*, osserva, "is not in itself a sufficient criterion for liveness; rather, it needs to be integrated with a notion of real space" [@discipio2021thinking, 177]. Ciò che caratterizza l'esperienza performativa è "the indivisibility of time-space coordinates in lived experience, in fact often evoked by the common language expression the *here and now* — moulded after the Latin *hic et nunc*" [@discipio2021thinking, 177].
Una performance dal vivo si realizza quando tutto accade "within and across a larger ecology of actions and perceptions that cannot be abstracted from a particular physical space of one's own material and cultural connotations" [@discipio2021thinking, 177].

Questa distinzione trova conferma nella storia della prassi. Il live electronics esisteva già prima dello sviluppo di sistemi informatici real-time ad alta velocità: le cybersonic console di Gordon Mumma negli anni Sessanta utilizzavano feedback elettronico analogico che operava su scale temporali differenti rispetto agli standard computazionali odierni, eppure costituivano autentiche performance dal vivo perché generavano e trasformavano suoni contestualmente all'esecuzione. Inversamente, i processori digitali degli anni Ottanta permettevano elaborazioni in tempo reale ma venivano impiegati anche in produzioni di studio per lavori su nastro, prive di dimensione performativa. Ciò che definisce il carattere *live* non è quindi la velocità operativa dei circuiti, ma la modalità d'uso: la presenza corporea, la condivisione dello spazio acustico, l'interazione con la contingenza irripetibile della situazione concertistica — dimensioni che trascendono qualsiasi parametro tecnico di latenza computazionale.

La definizione precisa di *live electronics* incontra problematiche che superano la mera dimensione terminologica. Secondo l'analisi di Agostino Di Scipio: "la possibilità di gestire mezzi elettronici ed elettroacustici in concerto — 'dal vivo' — non nasce certo negli anni 1960: i molteplici strumenti di liuteria elettronica della prima metà del '900 erano ovviamente destinati a tale impiego"[@discipio2021, 3.5].

L'espressione rappresenta piuttosto il tentativo di riunire sotto una singola denominazione **una molteplicità eterogenea di pratiche esecutive** sviluppatesi nel corso di almeno vent'anni del Novecento, attraverso contesti geografici e istituzionali profondamente differenziati.

Sovente la storiografia odierna inquadra nelle opere *Cartridge Music* (1960) e *Mikrophonie* (1964) la nascita della prassi del *live electronics*. Nei prossimi paragrafi ci soffermeremo su alcuni aspetti e caratteri che hanno contribuito alla nascita del *live electrinics*, primo fra tutti la crisi della *tape music*.

## La crisi della tape music (1950-1960)

Per comprendere la portata rivoluzionaria di opere come *Cartridge Music*, è necessario ricostruire il contesto da cui emergono. Durante tutti gli anni '50, la musica elettroacustica fu quasi esclusivamente *tape music* — musica fissata su nastro magnetico e composta attraverso tecniche di editing in studio.
Come osserva Gordon Mumma:

> "During the 1950s most composers treated magnetic tape in a 'hands-on' manner analogous to that of filmmakers. As with film, tape music was composed largely through editing."[@mumma1975, p. 292]

Il nastro magnetico era "il primo supporto di registrazione per il suono che fosse ragionevolmente editabile: poteva essere tagliato e giuntato con precisione"[@mumma1975, 292].
Questa modalità di lavoro confinava i compositori in dei veri e propri laboratori con macchinari particolarmente ingombranti. Fino al 1960 vi erano pochissime eccezioni all'uso del nastro magnetico come medium esclusivamente da studio [@mumma1975, 292]. Le opere risultanti venivano poi presentate al pubblico tramite diffusione radiofonica o in concerto attraverso altoparlanti — una situazione che creava evidenti tensioni con le aspettative del pubblico da concerto.

### Il rituale del concerto

Il problema non era meramente tecnico o estetico, ma toccava il cuore stesso della presentazione musicale. I compositori che lavoravano con nastro magnetico si trovavano continuamente a sperimentare modalità per presentare le proprie opere al pubblico [@mumma1975, p. 294]. La radiodiffusione e le registrazioni domestiche funzionavano bene perché permettevano all'ascoltatore di determinare autonomamente il grado di formalità con cui ascoltare. Ma la presentazione dal vivo poneva sfide del tutto diverse: il pubblico da concerto portava con sé aspettative tradizionali consolidate: "Audiences expect to see as well as hear a performance, and loudspeakers aren't much to look at."[@mumma1975, p. 294]

Questa tensione tra il medium acusmatico — il suono privo di fonte visibile — e le convenzioni del rituale concertistico tradizionale si inseriva, come ha osservato Nicola Bernardini, in una crisi più generale del rituale del concerto stesso [@bernardini1986, 62]. L'introduzione dell'elettronica dal vivo coincise, specialmente negli Stati Uniti e in Giappone, con un momento in cui il rituale del concerto veniva rivisto, modificato, distrutto, de-strutturato praticamente per ogni nuovo brano [@bernardini1986, 62].[^1]


[^1]: Non a caso le esperienze di Cage in ambito elettroacustico, come vedremo sotto, sono inscrivibili a pratiche multi-mediali spesso con teatro, danza e luci in un panorama di sperimentazione dove la musica assolve il ruolo di un unico senso, affidando il resto alle altre arti.
vedi sezione 1.boh.

I fattori scatenanti di questa crisi erano interconnessi [@bernardini1986, 62]: l'enorme influenza di John Cage sui suoi contemporanei (paragonabile all'influenza della scuola di Darmstadt); il progressivo indebolimento del linguaggio musicale, ormai giunto ai minimi termini, che metteva in crisi la stessa legittimità del compositore; l'assenza di una prassi strumentale codificata per gli strumenti elettronici, che aprì la strada a una partecipazione del pubblico molto più attiva; l'affermarsi dell'improvvisazione libera.

In questo contesto di trasformazione radicale, numerosi compositori cercarono alternative alla presentazione tradizionale di musica su nastro, sperimentando forme di live electronics che potessero ri-animare [@discipio2021thinking] la dimensione performativa della musica elettroacustica e rispondere alle aspettative di presenza e visibilità del pubblico.

### Uscire dallo studio

Joel Chadabe apre il capitolo "Out of the Studios" del suo *Electric Sound* con una domanda e una risposta emblematiche:

> "Question: 'How do you perform electronic music without tape?' Answer (said with a shrug of the shoulders and rising inflection): 'Take away the tape.'"[@chadabe1997, p. 81]

Questa necessità di "portare la musica elettronica fuori dallo studio"[@chadabe1997, p. 81] viene osservata anche da Gordon Mumma che in un articolo passa in rassegna quelle che oggi definiremmo "best practices" per uno studio modulare, con strumentazione trasferibile dal vivo per le perfomances, è sentita anche da Stockhausen. Egli in una conferenza del 1972, definisce *Mikrophonie I* come "electronic live music" in opposizione alla "electronic music which is produced in a studio"[@roth2023, 64, citando Cott & Stockhausen 1973]. Cage, parlando di *Cartridge Music* nel 1962, aveva coniato l'espressione "live electronic music" — probabilmente per la prima volta in assoluto, come nota Di Scipio [@discipio2021, Parte Terza].
L'inversione dei termini ("live electronic" vs "electronic live") probabilmente è sintomatica di approcci di lavoro e radici culturali differenti (l'idea di musica elettronica per un compositore come Stockhausen proveniente dallo studio WDR di Colonia è di gran lunga lontana da un'idea di elettronica di Cage); ciò che accomuna entrambe le opere è tuttavia l'esigenza di *animare*[@discipio2021thinking] la musica elettronica attraverso la performance dal vivo.

### Eccezioni tardive e transizione

Verso la fine degli anni '50 iniziarono ad apparire alcune eccezioni a questo dominio esclusivo della tape music da studio [@mumma1975, 292]. Alcuni compositori sperimentarono con suoni registrati su nastro presentati in concerto dal vivo insieme a strumenti o voci, mentre altri collocarono il nastro in situazioni performative innovative che si allontanavano dai riferimenti alla musica tradizionale. Emersero anche tecniche di studio che permettevano elaborazioni instantanee configurandosi di fatto come performance dal vivo, e casi in cui il nastro veniva impiegato esclusivamente per registrare e distribuire i risultati di performance che non lo utilizzavano come medium compositivo primario [@mumma1975, 292].

Il cambio decisivo avvenne quando alcuni compositori — Cage in primis — abbandonarono il nastro come premessa musicale ed esplorarono l'uso di dispositivi elettronici, da soli o in combinazione con strumenti acustici, come componenti per la performance dal vivo [@mumma1975, 292]. Secondo Mumma, questa transizione — dal nastro come medium compositivo primario all'elettronica come strumento performativo — segnò la nascita del live electronics come prassi distinta.  

Durante gli anni '60, la performance dal vivo con suoni amplificati di piccola entità, supportata dallo sviluppo di nuova strumentazione elettronica progettata specificamente per l'uso in concerto, divenne un'attività sempre più rilevante [@mumma1975, 297]. Questa prassi emergente attrasse gradualmente l'attenzione anche di coloro che, inizialmente impegnati filosoficamente con il medium del nastro magnetico, avevano in precedenza considerato il live electronics come un'impresa di scarso interesse [@mumma1975, 297].

## Due pionieri in un panorama globale

Tra il 1960 e il 1965, la scena della musica live electronics conobbe una significativa espansione a livello internazionale. Secondo le ricostruzioni storiche, in questo periodo l'attività si concentrò principalmente negli Stati Uniti, favorita da un vivace clima sperimentale e dalla precoce accessibilità della tecnologia a stato solido [@mumma1975, p. 296]. Accanto a figure americane come Robert Ashley, Alvin Lucier, Gordon Mumma e David Tudor, fiorivano esperienze parallele in Giappone con Takahisa Kosugi, in Francia con Gil Wolman, in Italia con Giuseppe Chiari e in Germania con Karlheinz Stockhausen. Fu in questo contesto di fermento globale che due composizioni, sebbene radicalmente diverse per filosofia e metodo, divennero emblematiche della nuova direzione performativa dell'elettronica: *Cartridge Music* (1960) di John Cage e *Mikrophonie I* (1964) di Karlheinz Stockhausen.

### Un incontro a Colonia: la sfida di Cage

Nell'ottobre del 1960, la prima esecuzione ufficiale di *Cartridge Music* di John Cage ebbe luogo a Colonia, nello studio dell'artista Mary Bauermeister. Secondo le ricostruzioni più attendibili, tra il pubblico era presente Karlheinz Stockhausen [@discipio2021, Parte Terza, p. 314]. Quel concerto rappresentò un momento di potente discontinuità per il panorama elettroacustico europeo. Cage, figlio di un inventore e privo di un solido supporto istituzionale, presentava una musica elettronica costruita non con i costosi strumenti degli studi specializzati, ma con cartucce di giradischi, microfoni a contatto e oggetti quotidiani come stuzzicadenti, molle e piume [@collins2020, p. 40; @chadabe1997, p. 81-82]. L'opera rivelava un intero universo di microsuoni, reso udibile attraverso una semplice amplificazione, e la sua partitura grafica, composta da fogli trasparenti sovrapponibili, istituiva un campo di possibilità aperto all'esplorazione dei performer piuttosto che un oggetto musicale rigidamente definito [@chadabe1997, p. 82]. In questo contesto, Cage coniò per la prima volta l'espressione "live electronic music" [@discipio2021, Parte Terza, p. 314], suggellando la rottura con il paradigma della musica su nastro.

Quattro anni dopo, Stockhausen diede la sua risposta a quella stessa intuizione con *Mikrophonie I*. Se Cage aveva lanciato la sfida della "microfonia" – l'esplorazione attiva del micromondo sonoro attraverso il microfono – Stockhausen ne colse il potenziale per reindirizzarlo all'interno di una poetica del controllo assoluto. L'opera impiega sì un principio simile di amplificazione di suoni minuti, ma lo incanala in un apparato esecutivo di straordinaria complessità e precisione. Sei performer, ciascuno con un ruolo rigidamente definito, agiscono su un tam-tam di grandi dimensioni: due lo eccitano con una gamma di oggetti, due ne esplorano la superficie con microfoni direzionali seguendo scrupolose indicazioni spaziali, e due manipolano filtri e potenziometri per trasformare il suono in tempo reale [@chadabe1997, p. 83-84; @mooney2017]. L'equipaggiamento non è più quello della tecnologia quotidiana, ma è altamente specializzato, incluso un raro filtro Maihak e un tam-tam Paiste appositamente selezionato [@roth2023, p. 61-66]. La partitura, basata sul principio della "moment-form", prescrive nel dettaglio ogni parametro, dalle distanze microfoniche alle frequenze dei filtri, trasformando l'intuizione esplorativa di Cage in un architettura sonora deterministicamente controllata [@chadabe1997, p. 83-84; @roth2023, p. 64].

### Una ricerca comune, due visioni del mondo

Entrambe le opere condividono la scoperta del microfono come strumento attivo, capace di rivelare un "nuovo mondo di risorse sonore" [@mumma1975, p. 296]. La ricchezza dei microsuoni amplificati in *Cartridge Music* era tale da rivaleggiare, come notato da Nicolas Collins, con le sonorità più laboriose prodotte negli studi elettronici europei [@collins2020, p. 40]. Tuttavia, le filosofie sottostanti non avrebbero potuto essere più distanti. Come sintetizza efficacemente Joel Chadabe, la musica di Cage proponeva un'"anarchia felice" basata su processi e giustapposizioni casuali, mentre quella di Stockhausen comunicava "controllo, tecnica ed expertise" [@chadabe1997, p. 83]. Questa divergenza è palpabile nelle loro dichiarazioni: Cage affermava che la sua partitura poteva servire a "esaminare musicalmente una vecchia Volkswagen" [@roth2023, p. 64], mentre Stockhausen sosteneva con forza che sostituire i filtri originali con simulazioni avrebbe distrutto l'unicità storica dell'opera [@roth2023, p. 64].

Questa divergenza di approccio si riflette persino nella terminologia scelta da ciascun compositore per definire la propria musica. Cage, già nel 1962, aveva coniato l'espressione 'live electronic music', ponendo l'accento sull'esperienza performativa ('live') come qualificante principale della musica ('electronic music'). Stockhausen, presentando Mikrophonie I nel 1972, la definì invece 'electronic live music', descrivendo così un genere musicale elettronico ('electronic music') che semplicemente avviene in diretta ('live'). Questa sottile ma significativa inversione lessicale cristallizza le due visioni: da un lato la performance come condizione esistenziale e filosofica, dall'altro il 'dal vivo' come modalità esecutiva di un'opera strutturata.

Sebbene non si possa stabilire un nesso causale certo, il potenziale incontro del 1960 a Colonia cristallizza un passaggio cruciale nella storia del live electronics. *Cartridge Music* funse da potente agente destabilizzante, introducendo nel cuore dell'Europa colta un'idea di elettronica povera, processuale e filosofica. *Mikrophonie I* rappresentò la risposta di un compositore istituzionale, che assorbì il principio della "microfonia" ma lo tradusse nel linguaggio del rigore, della complessità strutturale e del controllo tecnologico specialistico. Come osserva Agostino Di Scipio, erano entrambi "tempi di microfonia, anche se di tipo molto diverso" [@discipio2021, Parte Terza, p. 314]. Da questa comune intuizione nacquero così due traiettorie fondative, destinate a influenzare in modo duraturo lo sviluppo della musica elettroacustica dal vivo.


## Oltre la diade: accenni a un panorama plurale

Sebbene *Cartridge Music* e *Mikrophonie I* dominino la storiografia del live electronics, incarnando rispettivamente l'approccio DIY americano e il modello istituzionale europeo, la loro non fu una rivoluzione solitaria. Tra il 1960 e il 1970, ricerche parallele fiorivano in contesti geografici e culturali profondamente diversi, ciascuna elaborando soluzioni originali al problema di liberare la musica elettronica dal nastro magnetico e riportarla alla dimensione performativa del concerto.

In Italia, Luigi Nono trovò all'ExperimentalStudio der Heinrich-Strobel-Stiftung des Südwestfunks di Friburgo un modello alternativo sia rispetto agli studi radiofonici italiani che alle grandi istituzioni come IRCAM. Dal 1980, come ospite permanente dello studio — e dal 1983 come "artistic advisor" — Nono sviluppò un approccio basato sulla residenza artistica prolungata, trascorrendo ore innumerevoli in studio insieme a interpreti e tecnici in un processo di sperimentazione continua. Come avrebbe ricordato Hans Peter Haller, le parole ricorrenti di Nono erano "unsteady – emotional – searching – always different – always better". Questo "ecosistema di Friburgo" produsse, in meno di un decennio, una serie impressionante di capolavori che spaziavano dal colossale *Prometeo – Tragedia dell'Ascolto* alle più intime *Risonanze erranti*, opere in cui tecniche come i delay multipli e asimmetrici, i pitch shift microtonali e la dislocazione del suono nello spazio divennero la "firma" del compositore. Il modello Nono rappresentava una terza via: né il grande centro di ricerca centralizzato né l'autocostruzione DIY, ma piuttosto un'infrastruttura esistente disposta a investire tempo e risorse per permettere al compositore di sviluppare lentamente una forte visione estetica attraverso la sperimentazione profonda.

Negli Stati Uniti, intorno a figure come Gordon Mumma e Robert Ashley nella città di Ann Arbor, si stava formando un intero ecosistema basato sull'autocostruzione, la collaborazione orizzontale e la portabilità delle tecnologie. Nel 1958, Ashley e Mumma fondarono il Cooperative Studio for Electronic Music, uno studio domestico low-cost esplicitamente concepito per essere accessibile senza affiliazioni istituzionali o ingenti risorse economiche. Il Cooperative Studio forniva musica per filmmaker indipendenti, progettava "cybersonic equipment" per performance dal vivo, e incarnava un principio fondamentale: sacrificando la calibrazione precisa delle grandi attrezzature di laboratorio a favore delle dimensioni compatte dei componenti hi-fi ad alta impedenza, era possibile configurare un sistema dove "l'intero studio fosse alla portata del compositore comodamente seduto" [@mumma2015, p. 19-20].

Questo spirito cooperativo trovò espressione istituzionale nell'ONCE Festival (1961-1965), che presentò complessivamente ventinove concerti con sessantasette prime esecuzioni di circa centocinquanta opere di ottantotto compositori contemporanei [@mumma2015, p. 30]. Significativamente, quando alcuni membri del gruppo tentarono di ottenere supporto dalla University of Michigan, incontrarono "resistenza e persino animosità", con un boicottaggio quasi unanime dei concerti da parte dei docenti della School of Music durante il festival del 1963 [@mumma2015, p. 24, 29-30]. Il supporto venne invece dal Dramatic Arts Center, un'organizzazione locale non universitaria che manteneva un rapporto diretto e immediato con la comunità, senza overhead amministrativo [@mumma2015, p. 30]. L'ONCE Festival non era isolato, ma parte di un ricco ecosistema culturale che includeva lo Space Theatre di Milton Cohen (le cui produzioni culminarono alla Biennale di Venezia nel 1964), l'Ann Arbor Film Festival, e il Sonic Arts Union — quest'ultimo formato nel 1966 quando David Behrman e Alvin Lucier incontrarono Ashley e Mumma durante l'ONCE Festival del 1964 [@chadabe1997, p. 102].

Anche l'Italia vide fiorire scene parallele. A Roma, nel 1964, si formò il Gruppo di Improvvisazione Nuova Consonanza, una collaborazione internazionale che includeva i compositori americani Larry Austin, John Eaton e William Smith insieme agli europei Mario Bertoncini, Aldo Clementi, Franco Evangelisti, Roland Kayn e Ivan Vandor [@mumma1975, p. 316]. Nel 1966, sempre a Roma, venne organizzato MEV (Musica Elettronica Viva), ensemble principalmente di musicisti americani — tra cui Frederic Rzewski, Alvin Curran e Richard Teitelbaum — che nel giro di due anni passò dalla musica composta all'improvvisazione libera fino ad abbandonare nel 1968 "interamente le strutture musicali e sociali formali" [@mumma1975, p. 316]. A Firenze, Giuseppe Chiari compose dal 1964 al 1966 una serie di "azioni musicali" che facevano "largo impiego di microfoni a contatto" [@bernardini1986, p. 68].

Il Giappone sviluppò una scena particolarmente significativa. Takahisa Kosugi compose *Micro 1* (1961), opera per solo microfono, seguita da una serie di lavori poetici con elettronica radio-frequency e audio-frequency [@mumma1975, p. 299]. Toshi Ichiyanagi, che aveva studiato a New York con John Cage tra il 1956 e il 1961, al suo ritorno in Giappone compose un repertorio di opere per strumenti occidentali e giapponesi modificati elettronicamente, tra cui *Space* (1966), *Activities for Orchestra* (1967) e *Music for Living Spaces* (1970), quest'ultima un'installazione per l'Expo di Osaka [@mumma1975, p. 299]. Allo Studio NHK di Tokyo, Joji Yuasa utilizzò uno speciale magnetofono a cinque piste per opere come *Icon (on the source of white noise)* (1967), con diffusione del suono variabile da cinque a venticinque canali indipendenti [@discipio2021, Parte Seconda, p. 273]. La convergenza tra sperimentazione americana e giapponese trovò espressione simbolica nel Cross Talk Intermedia Festival, presentato a Tokyo nel febbraio 1969 nella struttura olimpica di Kenzo Tange progettata da Kenzo Tange, che vide la partecipazione di Mumma, Ashley, Lucier, Reynolds e VanDerBeek insieme a Ichiyanagi, Kosugi, Takemitsu e Yuasa [@mumma1975, p. 318].

Questo ricco e policentrico contesto rivela come il live electronics non fosse semplicemente l'antitesi della tape music, ma rappresentasse piuttosto un campo di sperimentazione multiplo in cui convergevano preoccupazioni estetiche, necessità tecnologiche, modelli organizzativi e visioni culturali profondamente diverse. I compositori attivi in questi vari contesti condividevano l'urgenza di superare la fissazione su nastro e recuperare la dimensione performativa, ma elaboravano soluzioni radicalmente diverse: dalla residenza artistica prolungata di Nono a Friburgo, agli studi cooperativi e ai festival indipendenti di Ann Arbor, dai collettivi improvvisativi romani alle collaborazioni transpacifiche. È a questo ecosistema nordamericano — caratterizzato dall'autocostruzione dei circuiti, dalla collaborazione orizzontale, dalla portabilità delle tecnologie e dalla necessità trasformata in filosofia — che dedicheremo il prossimo capitolo, esplorando come figure come Gordon Mumma, David Tudor, Alvin Lucier e i membri del Sonic Arts Union abbiano elaborato non solo nuove tecnologie, ma un modello completamente alternativo di prassi compositiva e performativa.

# Circuiti come partiture: tecnologia DIY e poetiche compositive nella scena americana (1960-1976)
## Contesto tecnologico-economico: dalla necessità alla scelta estetica

### Il transistor come rivoluzione tecnica

La nascita del live electronics americano negli anni Sessanta fu resa possibile da una rivoluzione tecnologica fondamentale: l'invenzione del transistor nel 1947 ai Bell Laboratories e la sua successiva commercializzazione. Come spiega Agostino Di Scipio, fu solo a metà del secolo che divennero disponibili materiali semiconduttori adatti a creare componenti circuitali compatti e versatili. L'elettronica precedente, basata sulle valvole termoioniche, non era riuscita a produrre sistemi musicali sufficientemente stabili ed efficienti, utili in contesti generici e non legati all'esperienza del singolo inventore. La nuova elettronica a transistor, sfruttando il rapporto esponenziale tra tensione in ingresso e corrente in uscita, si presentava invece come la soluzione a quei problemi, aprendo la porta a "possibilità applicative prima impensabili"[@discipio2021, 279].

Questa transizione tecnologica ebbe conseguenze dirette per i compositori. David Behrman ricorda che verso il 1965, lavorare con circuiti autocostruiti era una necessità, poiché non c'erano *synth* disponibili in vendita nel mercato. Tuttavia, Behrman aggiunge una nota cruciale: "You didn't have to have an engineering degree to build transistorized music circuits"[@collins2020, Foreword]. I transistor non solo miniaturizzarono l'elettronica, ma la democratizzarono, rendendola accessibile.

### Il surplus bellico come materiale compositivo

La Seconda Guerra Mondiale lasciò in eredità un'abbondanza di componenti elettronici militari dismessi, disponibili a prezzi irrisori. Gordon Mumma ricorda come David Tudor passasse molto tempo nei negozi di surplus militare a procurarsi transistor e condensatori insoliti. Assemblandoli, si otteneva un circuito unico—un oscillatore, un modulatore—la cui risposta sonora non era replicabile. Sostituendo anche un solo transistor con un altro, il circuito cambiava, dotando ogni strumento di una personalità sonora specifica e irripetibile[@nakai2021, 173-174].

Questa caratteristica—l'**irriproducibilità** intrinseca dei componenti surplus—non fu vista come un limite, ma divenne un valore estetico. You Nakai sintetizza: "Specific components composed specific instruments, which in turn composed specific sound systems—so it was **bias all the way down**"[@nakai2021, 174]. L'approccio americano si distingueva radicalmente dagli studi europei istituzionali: dove Colonia o l'IRCAM perseguivano la precisione e la riproducibilità attraverso equipaggiamento professionale costoso, la scena americana abbracciava l'imperfezione produttiva dei componenti di scarto.

Il contesto economico era tale che, come ricorda Robert Ashley, non si aveva accesso a nulla, se non all'elettronica di base. Prima della fine degli anni Sessanta, i sintetizzatori commerciali semplicemente non esistevano e il mercato era dominato da rivenditori come Lafayette Radio Electronics, che vendeva kit per hobbisti a prezzi accessibili. È significativo che David Tudor conservasse meticolosamente le ricevute per l'acquisto di kit come l'amplificatore a tre transistor PK-522 e il mixer microfonico PA-292, acquistati per pochi dollari[@nakai2021, 121].

Quando i primi sintetizzatori commerciali, come il Moog e il Buchla, arrivarono sul mercato, molti compositori del Sonic Arts Union li rifiutarono esplicitamente. Gordon Mumma tracciava una distinzione fondamentale tra la "explorer tendency" dei musicisti della Cunningham Dance Company e l'omogeneità rappresentata dalla produzione di massa e dai synth commerciali. In questa visione, "The idea of 'product' was fundamental in that regressive cultural tide"[@chadabe1997, 102].

### John Cage: Dal Prepared Piano ai Microsuoni Amplificati**

Se nel capitolo precedente John Cage è emerso come pioniere a livello globale, in dialogo e contrapposizione con Stockhausen, per comprendere la specificità del modello americano è necessario considerarlo come l'ispiratore filosofico di un intero movimento (infatti come vedremo in seguito è poi la figura di David Tudor a catalizzare le proposte di Cage in una nuova prassi compositiva). La sua ricerca, iniziata ben prima del seminale *Cartridge Music* (1960), gettò le basi per un approccio alla tecnologia musicale che fosse accessibile, processuale e radicalmente performativo.

La formazione di Cage fu atipica e profondamente segnata da una familiarità con la tecnologia fin dagli anni '30. Figlio di un inventore, assisteva il padre nelle ricerche per i brevetti, sviluppando "una sufficiente padronanza dei concetti e del vocabolario del campo per comunicare con i professionisti" [@mumma2015, 167]. Questo retroterra spiega la sua disinvoltura nell'approccio alla tecnica. La sua curiosità per i nuovi media si manifestò precocemente: tra il 1932 e il 1933 presentava programmi radiofonici a Los Angeles, e nel 1936 lavorava come apprendista montatore con il filmmaker Oskar Fischinger, sperimentando tecniche di sincronizzazione suono-immagine che anticipavano il lavoro sul nastro magnetico [@mumma2015, 167].

Il percorso di Cage verso il live electronics non fu un fulmine a ciel sereno, ma il culmine di una ricerca ventennale sul suono, la performance e la tecnologia, caratterizzata da una grande coerenza di pensiero.

1.  **Percussioni e Prepared Piano (anni '40):** Già nel 1939, con *First Construction in Metal*, Cage utilizzava "ceppi dei freni e altro ferro vecchio recuperato dalle discariche" (Collins, 2020, p. 40). Il ricorso al prepared piano nello stesso decennio, oltre a creare sonorità inedite, rispondeva a un'esigenza pratica: "avere una risorsa multi-timbrica senza il duro lavoro di spostare strumenti a percussione" (Mumma, 2015, p. 162). L'idea di trasformare oggetti di uso comune in strumenti musicali era già pienamente presente.

2.  **La serie "Imaginary Landscape" (1939-1952):** Questa serie rappresenta il vero e proprio laboratorio delle sue future idee. *Imaginary Landscape No. 1* (1939) è storicamente significativa come "il primo brano documentato di musica a presentare il DJ come un performer musicale" (Collins, 2020, p. 40), utilizzando giradischi a velocità variabile. Di Scipio (2021a) nota come l'uso performativo del grammofono fosse un'idea dadaista che Cage mutuò da László Moholy-Nagy. Un passaggio cruciale avvenne nel 1942 con *Imaginary Landscape No. 3*, che segnò "il primo uso di piccoli suoni amplificati" da parte di Cage [@mumma2015, 169]. La serie culmina con *Imaginary Landscape No. 4* (1951) per dodici radio, che, insieme a *Radio Music* (1952) e *Music Walk* (1958), esplorò sistematicamente "il ricevitore radio come strumento per la performance dal vivo" (Mumma, 1975, p. 293).

3.  **Il periodo del nastro: *Williams Mix* (1952):** Sebbene si tratti di un'opera su nastro, *Williams Mix* è fondamentale per la sua metodologia. Cage, con l'aiuto di Earle Brown e David Tudor, creò una biblioteca di suoni catalogati (città, campagna, suoni elettronici, etc.) e utilizzò l'I Ching per decidere tramite operazioni casuali "che tipo di suono utilizzare, su quali tracce posizionarlo, e le durate di suoni e silenzi" (Chadabe, 1997, p. 56). Questo approccio, volto a definire un "territorio" sonoro (in questo caso, il mondo) piuttosto che un oggetto musicale finito, sarebbe diventato centrale nella sua filosofia (Chadabe, 1997, p. 83).

Tutti questi fili si riuniscono in *Cartridge Music*. Alla fine degli anni '50, Cage coinvolse David Tudor nella ricerca di trasduttori elettronici, componenti che andavano diffondendosi con la tecnologia a transistor [@mumma2015, 170]. 
Come nota Gordon Mumma, questo lavoro, assieme alla Music for Amplified Toy Pianos, fu eseguito frequentemente da Cage e David Tudor, essendo "a considerable stimulus to experimentation in live-electronic music"[@mumma1975, 295]. Nicolas Collins sintetizza che la sorprendente ricchezza di questi "microsuoni" enormemente amplificati rivaleggiava con le sonorità sintetiche e costose degli studi europei e "opened the ears of a generation of sound artists to the splendor of the contact mike"[@collins2020, 40].
La partitura di Cartridge Music si basava su un sistema indeterminato ma strutturato. Essa consisteva in materiali grafici su fogli trasparenti che i performer potevano sovrapporre in combinazioni diverse per definire la struttura di una specifica esecuzione. Questo approccio permetteva a Cage di strutturare diverse situazioni performative, incluse quelle collaborative.
David Tudor affrontò queste partiture grafiche con un rigore quasi scientifico, sviluppando un sistema personale per la loro interpretazione. Come documenta You Nakai, Tudor creò template e righelli su misura e elaborò "nomographs" (tradotto nomografi)—sistemi di misurazione grafica—applicando una polarità semplice/complesso a sei parametri musicali[@nakai2021, varie pagine]. In questo modo, la notazione grafica non eliminava la precisione, ma la spostava dalla prescrizione del compositore all'interpretazione attiva e metodica del performer.

L'eredità di Cage per il modello americano che di lì a poco sarebbe fiorito ad Ann Arbor è quindi triplice: filosofica (L'apertura a tutti i suoni e l'uso di processi indeterminati), pragmatica (L'uso della tecnologia quotidiana e accessibile, in opposizione agli apparati degli studi istituzionali) e sociale (La definizione di un "territorio" performativo che valorizza l'esplorazione collettiva).
Queste idee, concretizzatesi nella prassi di David Tudor, avrebbero trovato nel fertile ecosistema di Ann Arbor il terreno ideale per evolversi in un vero e proprio movimento.

## Circuit Music: lo schema circuitale come partitura

### Dalla notazione grafica al diagramma di sistema

Ezra Teboul definisce la circuit music come una musica il cui sistema notazionale primario è costituito da schemi circuitali e diagrammi, anziché da partiture tradizionali. In questa prospettiva, il circuito cessa di essere un semplice strumento esecutivo per diventare esso stesso la partitura, ridefinendo radicalmente la figura del compositore come progettista di sistemi generativi di comportamenti sonori[@Teboul2023].

La filosofia compositiva di David Tudor incarnava perfettamente l'etica del circuit music. Come spiega in un'intervista del 1972: "I try to find out what's there—not to make it do what I want, but to **release what's there**. The object should teach you what it wants to hear"[@collins2004]. Questa inversione della relazione composer-instrument,dove lo strumento "insegna" al compositore piuttosto che essere piegato alla volontà compositiva, divenne centrale per la pratica del live electronics. In questo Tudor è stato un catalizzatore dell'indeterminazione di Cage, portando l'indeterminazione come essenza stessa della convivenza con la macchina nella performance. 

You Nakai riporta come Tudor, in un workshop, esortasse a servirsi dello stato naturale dei componenti per ciò che offrono realmente, non per ciò che dovrebbero fare secondo le specifiche del progettista[@nakai2021, 55]. Questo metodo empirico valorizzava la scoperta diretta e l'ascolto rispetto all'applicazione di un progetto astratto.

### La transizione di Tudor: da pianista a costruttore di strumenti

La trasformazione di David Tudor da virtuoso del pianoforte a pioniere del live electronics è ben documentata. You Nakai ripercorre questa evoluzione, dalla sua celebre attività di interprete di Cage, Stockhausen e Boulez, alla sua maturazione come compositore di opere elettroniche live come Bandoneon! e Rainforest.

Il punto di svolta si colloca nella sua realizzazione di Variations II di Cage. Tudor stesso scrisse di aver concepito il pianoforte amplificato non come un pianoforte con l'aggiunta dell'elettronica, ma come un autentico strumento elettronico. Utilizzando microfoni a contatto per amplificare i micro-suoni interni dello strumento e creando circuiti di feedback, il comportamento sonoro risultante diveniva indeterminato: non era possibile prevedere con esattezza la qualità o la durata dell'output, si poteva solo sperare di influenzarlo.

### *Fluorescent Sound* (1964) e *Bandoneon!* (1966)

You Nakai identifica in *Fluorescent Sound* (13 settembre 1964) una pietra miliare, trattandosi della "the first work in which he credited himself as a 'composer'"[@nakai2021, 210-211]. L'opera impiegava 75 scatole di fusibili per controllare luci fluorescenti, esplorando i suoni prodotti dai loro starter quando sovraccaricati. La logica della circuit music è qui evidente nel titolo stesso: "fluorescent sound", inizialmente una semplice categoria di componente, divenne in retrospettiva un nome proprio, in un processo per cui, come nota Nakai, "synecdoche, the part had claimed a new whole" (ibid.).


*Bandoneon! (Bandoneon Factorial)*, eseguito il 14 ottobre 1966, fu la prima opera in cui Tudor si accreditò come compositore anche nelle note di programma. Il sistema era di una complessità estrema, articolato su 15 canali di processing. La performance, tuttavia, si rivelò un disastro tecnico a causa di circuit boards cablati al contrario, al punto che un testimone la ricordò come "one of the biggest fuckups of the century". Eppure, Tudor, confermandosi "the ultimate performer", riuscì a salvare la situazione attraverso l'improvvisazione, nonostante il collasso totale del sistema elettronico previsto.


## Gordon Mumma e i Cybersonics: l'integrazione strumento-circuito

### La filosofia cybersonica

Gordon Mumma sviluppò un approccio distintivo al live electronics che chiamò **cybersonics**: "live-electronic feedback principle by which some aspect of the sound is fed back into the electronic process, thus modifying sound *by characteristics derived directly from the sound itself*"[@mumma2015]. Questa definizione indica un sistema **autoreattivo** dove il processamento elettronico risponde in tempo reale alle caratteristiche del suono che sta processando, creando loop di feedback complessi.
L'opera paradigmatica è *Hornpipe* (1967), per corno francese con circuiteria cybersonica portatile. Mumma spiega: 

> "The electronic circuitry senses the tones from the horn, and modifies them to produce additional sounds. The modifications are determined by characteristics of the horn tones—their loudness, their pitch, and their timbre"[@mumma1975, 324]. 

Il sistema non applicava preset effects, ma **rispondeva** dinamicamente al materiale sonoro in ingresso.

### La Cybersonics Company e la costruzione collaborativa

Nel 1965, Mumma fondò con l'ingegnere William Ribbens la **Cybersonics Company**, producendo dispositivi custom per vari compositori. Il più famoso fu il **Spectrum Transfer**, un ring modulator versatile costruito per David Tudor, che divenne, come scrive Nicolas Collins, un contributo fondamentale al canone della live electronic music, ampiamente utilizzato da Tudor per decenni[@collins2020, 265]. You Nakai documenta come Mumma riconoscesse i propri strumenti da uno "stile costruttivo" riconoscibile, una sorta di firma artigianale che rivelava l'approccio personale di ogni costruttore di hardware.

### *Mesa* (1966) e la collaborazione Tudor-Mumma

*Mesa* (1966) fu composta per il **bandoneon** di David Tudor processato attraverso circuiteria Cybersonics costruita da Mumma. La scelta del bandoneon fu strategica, dovuta alla sua natura bi-strumentale, essendo uno dei pochi strumenti con due lati distinti. Mumma spiegò che questa caratteristica offriva tre qualità ideali per il processing: uno spettro complesso e fluttuante, la capacità di un lato di modulare l'altro, e le differenze di fase tra i due lati.[@nakai2021, 230-231].

L'opera fu presentata ai **9 Evenings: Theatre & Engineering** (ottobre 1966, 69th Regiment Armory, New York), un evento cruciale che mise in contatto artisti sperimentali con ingegneri dei Bell Labs. Mumma ricorda: "There was this magic triangle between the scientists and the artists and the hardware"[@mumma2015].

## Poetiche divergenti all'interno di un'estetica condivisa

### Alvin Lucier: fenomeni fisici e processi naturali

Alvin Lucier sviluppò un approccio al live electronics che privilegiava l'esplorazione di **fenomeni fisici** piuttosto che la costruzione di strumenti complessi. La sua opera più famosa, *I Am Sitting in a Room* (1969), usava il **feedback acustico** come materiale compositivo: "I am sitting in a room different from the one you are in now. I am recording the sound of my speaking voice and I am going to play it back into the room again and again until the resonant frequencies of the room reinforce themselves so that any semblance of my speech, with perhaps the exception of rhythm, is destroyed"[@lucier1988].

In *Music for Solo Performer* (1965), le **onde cerebrali** (EEG) amplificate venivano utilizzate per attivare strumenti a percussione attraverso trasduttori. Come osserva Collins questo approccio rendeva il performer parte di un sistema di feedback complesso che coinvolgeva onde cerebrali, audio e acustica. Il compositore non controllava direttamente il suono, ma progettava un sistema in cui fenomeni naturali—come le risonanze ambientali o l'attività cerebrale—diventavano i veri "interpreti".[@collins2004].

### Robert Ashley: electronic music theater

Robert Ashley sviluppò quello che definì **electronic music theater**, dove la tecnologia elettronica assumeva una funzione teatrale più che strettamente strumentale. Opere come *The Wolfman* (1964) e *in memoriam... Crazy Horse* (1964) usavano feedback vocale estremo per creare "sonic situations" piuttosto che composizioni nel senso tradizionale.

Ashley spiegava che l'idea del teatro musicale elettronico live nasceva dalla possibilità di creare una situazione teatrale a partire dal feedback elettronico[@chadabe1997, 87]. In *in memoriam... Crazy Horse*, cantava ad alto volume vicino a un microfono cercando deliberatamente il feedback, imparando a controllarne l'intensità salendo e scendendo con la voce. In questo contesto, il performer diventava un "operatore di feedback" più che un musicista convenzionale.

### David Behrman: circuiti semi-autonomi

David Behrman esplorò sistemi con **indeterminacy incorporata** nei circuiti stessi. In *Runthrough*, l'utilizzo di fotocellule permetteva di generare suoni attraverso le ombre proiettate dalle mani dei performer, creando un sistema in cui il compositore definiva la struttura ma il comportamento sonoro preciso emergeva da azioni imprevedibili[@collins2020].

Come scrive nella prefazione a *Handmade Electronic Music*, esisteva una tradizione che da Tudor e Mumma portava a costruire i propri dispositivi elettronici, collegandosi esplicitamente alla tradizione americana della costruzione strumentale che risale fino a Harry Partch. Behrman colloca così la pratica dell'hacking hardware all'interno di una precisa genealogia culturale americana[@collins2020, Foreword].

## Organizzazione sociale: da Ann Arbor al Sonic Arts Union

### Il Cooperative Studio for Electronic Music (Ann Arbor, 1960)

Gordon Mumma fondò nel 1960 ad Ann Arbor il **Cooperative Studio for Electronic Music**, il primo studio indipendente del suo genere negli Stati Uniti. Come spiega Mumma, l'idea centrale era che gli individui potessero riunirsi e mettere in comune le risorse, dove il termine "cooperativo" aveva precise ramificazioni politiche che il gruppo considerava necessarie[@mumma2015].

Lo studio si distingueva dai modelli europei per la sua essenziale **mobilità**:  L'attrezzatura non era installata in modo permanente ma progettata per essere portatile, consentendo di trasportarla per performance in diversi spazi. Questa caratteristica fu resa possibile dall'avvento della tecnologia a transistor, che ridusse i costi energetici e aumentò l'affidabilità rispetto ai precedenti sistemi a valvole[@Dewar2018].

### Il ONCE Festival (1961-1965)

Il **ONCE Festival** (Ann Arbor, 1961-1965) fu il principale venue per la scena sperimentale di Ann Arbor. Organizzato inizialmente dal poeta Robert Waldrop, divenne rapidamente un punto di riferimento internazionale. Mumma ricorda: "ONCE became a kind of beacon. People would come from all over—Cage, Tudor, Charlotte Moorman, Takehisa Kosugi"[@mumma2015].

Il festival si caratterizzava per la scelta di sedi non convenzionali, utilizzando spazi come il seminterrato del Dramatic Arts Center, magazzini e aree all'aperto, evitando deliberatamente le tradizionali sale da concerto. Questa scelta rappresentava una critica implicita alle istituzioni musicali accademiche che si erano rifiutate di sostenere l'iniziativa.

### Il Sonic Arts Union (1966-1976)

Fondato nel 1966 da Gordon Mumma, Robert Ashley, David Behrman e Alvin Lucier, il Sonic Arts Union traeva la sua filosofia dall'uso del termine "sonic", che evocava tutti i suoni possibili, non solo quelli musicali in senso tradizionale[@chadabe1997, 102].

Mumma descrive la formazione del gruppo come frutto di una performance congiunta nel 1966, dopo la quale compresero di condividere un apprezzamento per le rispettive differenze estetiche. Questa diversità estetica divenne la base del collettivo. Lucier ricorda come si eseguissero i pezzi l'uno dell'altro, adattando le opere come Runthrough di Behrman o Mesa di Mumma anche in assenza dell'autore.
Il Sonic Arts Union intraprese tournée internazionali estenuanti ma fondamentali, toccando città come Roma, Oslo e Londra, con un ritmo serrato di sedici performance in trenta giorni durante il tour europeo del 1969. Questi viaggi furono cruciali per diffondere in Europa l'approccio americano al live electronics.
Il gruppo si sciolse nel 1976 quando i membri presero posizioni accademiche: Ashley divenne direttore del Center for Contemporary Music al Mills College, Lucier si unì alla faculty della Wesleyan University, Mumma all'University of California, Santa Cruz, e Behrman al Mills College[@chadabe1997, 102].

### Composers Inside Electronics (1973-1990s)

Il collettivo Composers Inside Electronics si formò nel 1973 a partire da un workshop dedicato a Rainforest di David Tudor. Secondo Nicolas Collins, i partecipanti, tra cui John Driscoll e Paul DeMarinis, imparavano facendo: smontavano gli strumenti di Tudor, ne costruivano versioni proprie e ne comprendevano il funzionamento attraverso la replicazione[@collins2004].

Questo modello pedagogico-collaborativo si rivelò fondamentale per trasmettere il sapere tecnico a una nuova generazione. Collins sottolinea come l'hacking hardware spostasse l'attenzione dall'inventare nuovi prodotti all'esplorazione di processi, con circuiti e tecniche che formavano un patrimonio di conoscenza condivisa e non protetta da copyright[@collins2020].

## Portabilità e performance: l'estetica della precarietà

### Dal studio alla scena

Come già anticipato nel capitolo 1, la musica su nastro soffriva di un problema fondamentale: la sua immobilità. Gli studi istituzionali, come il Columbia-Princeton Center, erano installazioni massive e fisse. Fu la tecnologia a transistor, con la sua miniaturizzazione[@Dewar2018], l'affidabilità e i ridotti costi energetici, a rendere finalmente possibile portare l'elettronica fuori dallo studio.
Pioniere in questo fu David Tudor, il cui lavoro con la Merce Cunningham Dance Company richiedeva setup portatili, progettati secondo criteri di flessibilità, portabilità e basso costo. Gordon Mumma portò avanti questa ricerca costruendo per Hornpipe (1967) una console cybersonica indossabile, una "belt-box" che permetteva al performer di suonare il corno con le mani libere[@mumma1975, 324].
Questa portabilità, tuttavia, aveva un prezzo: i setup erano notoriamente instabili. Come riportato in una testimonianza citata da Collins, i circuiti potevano sembrare grovigli di fili e richiedevano cure costanti, paragonabili a quelle di "un'anziana signora con tre dozzine di gatti". La performance diventava così un evento rischioso, in cui il fallimento tecnico era un'evenienza sempre presente[@collins2020].

L'episodio leggendario del disastroso debutto di Bandoneon! - che avevamo accennato sopra - dovuto a circuit boards cablati al contrario, è esemplare. Eppure, questa precarietà non era considerata un difetto, ma una caratteristica intrinseca all'approccio esplorativo del gruppo, in netto contrasto con l'omogeneità e la stabilità dei sistemi commerciali.

Prendiamo come esempio un altro lavoro fondamentale di Tudor: *Rainforest* (1968) Questo rappresentò una soluzione elegante al problema della portabilità: invece di trasportare strumenti elettronici pesanti, Tudor usava **transducers** (Rolen-Star) applicati a "physical materials" — oggetti trovati sul posto — trasformandoli in **instrumental loudspeakers**[@nakai2021, 246].

You Nakai spiega che gli oggetti, scelti per le loro specifiche caratteristiche risonanti, non erano semplicemente amplificati, ma diventavano parte attiva e parametrica del sistema sonoro. Nella versione collaborativa Rainforest IV, ogni performer selezionava i propri "oggetti risonanti", creando un ecosistema sonoro unico per ogni esecuzione. Questa soluzione incarnava perfettamente l'etica della circuit music: progettare un sistema che si adattasse e valorizzasse le proprietà specifiche dei materiali disponibili localmente, piuttosto che imporre un comportamento standardizzato attraverso attrezzature industriali.

## Resistenza alla corporatizzazione e "post-optimality"

### Il rifiuto dei sintetizzatori commerciali

Quando i sintetizzatori commerciali—Moog, Buchla, ARP—arrivarono sul mercato alla fine degli anni Sessanta, molti membri del Sonic Arts Union li rifiutarono. David Behrman spiegò perché: sintetizzatori commerciali "tend, when used alone, to produce sounds which are quickly used up by our culture (and become clichés)"[@collins2020]. L'efficienza produttiva dei sistemi modulari standardizzati era vista come una **trappola estetica**.

Gordon Mumma articolò questa critica in termini quasi politici: "The idea of 'product' was fundamental in that regressive cultural tide"[@chadabe1997, 102]. Il passaggio dalla costruzione artigianale alla produzione di massa rappresentava non solo un cambiamento tecnologico, ma una **trasformazione di valori**: dalla specificità del fatto-a-mano all'omogeneità del mass-produced.

### "Post-optimality" e l'estetica del junk

Ezra Teboul conia il termine **post-optimality** per descrivere questa scelta deliberata dell'inefficienza: "circuit music as utopia—a glimpse at technology after the profit motive"[@Teboul2023]. L'uso di componenti surplus militari, di kit economici, di self-built circuits non era solo necessità economica, ma rappresentava una **posizione critica** verso la logica della produzione capitalistica.

Barbara Haskell, in un saggio del 1984, identificò un'**aesthetic of junk** nella scena americana: "assemblage, scrap materials, things that the society has discarded"[@haskell1984]. Questa estetica collegava i compositori del live electronics a un più ampio movimento artistico americano—da Rauschenberg a Fluxus—che valorizzava i materiali di scarto come critica implicita alla cultura del consumo.

Nicolas Collins aggiorna questa analisi: "In the old days, there was no distinction between high tech and low tech—everything was simply 'tech.' The transistor, a little later the integrated circuit, and then the microcomputer [...] Their building blocks (integrated circuits), however, were pretty cheap and almost understandable"[@collins2020, 3]. La tecnologia era **accessibile intellettualmente** oltre che economicamente.

### DIY vs DIT: community e condivisione

Il modello del "Do It Yourself" americano, pur enfatizzando l'indipendenza, era in realtà profondamente **collettivo**. Collins preferisce il termine **DIT (Do It Together)**: "They bent the precarity of their conditions of access [...] and created a circuit of long lasting friendships"[@collins2020]. La circolazione di schemi circuitali avveniva "like samizdat literature"[@collins2020]—copiate a mano, fotocopiate, condivise informalmente.

Questa rete di condivisione si estese globalmente. Collins documenta: "Mills College (California): Behrman, Ashley students. Wesleyan University: Lucier students (Collins, Kuivila). CalArts: Serge Tcherepnin students"[@collins2020]. Il know-how tecnico si diffondeva attraverso workshop, residenze, collaborazioni informali—un network transnazionale basato sulla **reciprocità** piuttosto che sul mercato.

## Dalla notazione al network: un nuovo modello di autorialità

### La ridefinizione del "comporre"

La pratica del circuit music richiese una ridefinizione radicale di cosa significhi "comporre". David Tudor riflette su questa trasformazione: "Composing instruments that make music, rather than making music, is an act one step removed"[@nakai2021, 138-139]. Il compositore non scrive più *suoni*, ma progetta *sistemi* che generano comportamenti sonori.

Questo spostamento autoriale fu teorizzato da Cage. Come documenta Nakai, Tudor citava Busoni per descrivere la propria liberazione: "Notation is an invention of the devil"[@nakai2021, 139]. Opere come *Fontana Mix*, *Music Walk*, *Bussotti Piano Piece No. 3* liberarono Tudor dalla "devil's invention" della notazione tradizionale, permettendogli di esplorare un nuovo tipo di autorialità.

### Co-composizione e instrumental agency

La pratica del live electronics introduceva quello che Tudor chiamava **co-composizione**. Discutendo *Variations II* di Cage, Tudor osservò: "When you go that far, then in a sense you are co-composer"[@nakai2021, 138]. Il confine tra compositore e performer, tra progetto e realizzazione, si sfumava.

Ma c'era un terzo "autore": lo **strumento stesso**. La filosofia di Tudor—"the object should teach you what it wants to hear"[@collins2004]—attribuiva agency ai dispositivi elettronici. Questo non era antropomorfismo ingenuo, ma riconoscimento che ogni circuito ha un **bias**, proprietà intrinseche che determinano il range dei comportamenti possibili.

Mumma spiegò: "The equipment imposes control"[@nakai2021, 139]. I compositori del live electronics non cercavano di superare o nascondere questi limiti, ma li **esploravano** come materiale compositivo. Ogni resistore, ogni condensatore, ogni transistor surplus con le sue tolleranze specifiche contribuiva all'identità sonora del sistema.

### Network come forma compositiva

Il modello organizzativo del Sonic Arts Union e di Composers Inside Electronics suggeriva che la **rete stessa** potesse essere vista come una forma compositiva allargata. Non singoli autori che producono opere discrete, ma un ecosistema di pratiche condivise, strumenti scambiati, conoscenze circolanti.

Collins scrive: "The circuits and techniques described in this book are not copyrightable 'intellectual property'—they form part of a community of shared knowledge"[@collins2020, 6]. Questo "commons" tecnologico era un'alternativa esplicita alla logica del copyright e del brevetto—un modello più vicino al **software libero** che al mercato delle commodities.

In questo senso, la scena americana del live electronics anticipò di decenni questioni che sarebbero diventate centrali nell'era digitale: open source, peer production, commons-based economy. Il circuito non era solo una *partitura*, ma un **protocollo** per una nuova forma di produzione culturale.

## Un'eredità radicale

### Democratizzazione dei mezzi di produzione

Il contributo fondamentale della scena americana fu la **democratizzazione dell'accesso** ai mezzi di produzione elettroacustica. Come sintetizza Collins: "You didn't have to have an engineering degree to build transistorized music circuits"[@collins2020, Foreword]. Questo spostamento—dall'ingegneria specializzata all'bricolage informato—aprì il live electronics a chiunque avesse curiosità tecnica e accesso a componenti di base.

Gordon Mumma dimostrò che "era possibile fare musica elettroacustica sofisticata al di fuori delle grandi istituzioni, che il compositore poteva essere anche l'ingegnere, che l'equipment poteva essere portatile, che la tecnologia poteva essere un partner collaborativo piuttosto che un servitore passivo"[@mumma2015]. Questa triplice liberazione—istituzionale, tecnica, estetica—definì l'approccio americano.

### Circuit music come pratica critica

Ma il circuit music non fu solo una soluzione pragmatica a vincoli economici. Fu una **pratica critica** che interrogava il rapporto tra tecnologia, autorialità e produzione culturale. La scelta di componenti surplus, di self-built instruments, di sistemi instabili era un rifiuto della logica del "prodotto" a favore di un'etica del processo.

Come osserva Teboul, il circuit music offriva "a glimpse at technology after the profit motive"[@Teboul2023]—una visione utopica di come potrebbe funzionare la produzione tecnologica al di fuori delle logiche capitaliste. Questa dimensione politica, spesso implicita, divenne più esplicita negli anni Settanta con il movimento DIY punk e negli anni Duemila con il circuit bending.

### Legacy contemporaneo

L'eredità del live electronics americano (1960-1976) è profondamente presente nella musica elettronica contemporanea, anche se spesso non riconosciuta. Il laptop music, la cultura del circuit bending, l'hardware hacking, le pratiche di live coding—tutti questi approcci riflettono principi sviluppati da Tudor, Mumma, Lucier, Ashley, Behrman.

Keith Potter, nell'obituario per Hugh Davies, osservò che l'approccio "innovative, do-it-yourself, lo-fi" di Davies—e per estensione dell'intera scena americana—"in several respects prefigured today's laptop culture"[@davies2005]. La differenza è che oggi questi approcci sono **scelte estetiche** più che necessità economiche. Ma la filosofia sottostante rimane: la tecnologia come materiale da esplorare, non come servizio da consumare.

\clearpage

# CAP. 3: IRCAM E IL MODELLO ISTITUZIONALE

## 3.1. Genesi politica di IRCAM (1970–1977)

## 3.2. Soft power e innovazione tecnica

## 3.3. Il 4X e *Répons* (1981)

## 3.4. Limiti del modello: ricerca vs arte


# CONCLUSIONI

## Sintesi dei percorsi

## Live electronics come specchio di visioni del mondo

## Prospettive future


# Appendice A - Interviste dalle vite "dal vivo"

## Giuseppe Silvi

#### Secondo te è considerabile live electronics?

Per rispondere a questa domanda devo prima rispondere a me stesso, a una domanda più generale: «che cos'è live electronics?» Mi soffermo a pensare alla formula aggettivo-sostantivo utilizzata per segnare un passaggio da "electronics" a "live electronics". E mi viene in mente un parallelismo storico: il momento in cui nella produzione discografica --- quindi nelle logiche di un'industria --- alla produzione "stereo" si è affiancata quella "true stereo". Le ragioni storiche ora sono semplici: la stereofonia era praticata da tempo ma l'introduzione di supporti di distribuzione in larga scala a due "tracce", quella che avrebbe dovuto coronare il sogno del teatro a casa (mediante segnale stereofonico, per intendersi), aveva anche offerto un dispositivo, o una serie di dispositivi --- presenti e futuri --- le cui possibilità tecniche non erano massivamente comprese --- nel senso che la comprensione ottenuta dalla nicchia che le avevano stimolate non erano divenute di massa come la disponibilità. Il paradosso tra possibilità e disponibilità è intrinseco nello sfruttamento tecnologico operato dall'industria, motivo per cui la "vera" discografia stereo per distinguersi da, per dirne uno, "Sgt. Peppers" iniziò ad usare "true stereo": aggettivo-sostantivo. È la formula della mediocrità industriale imperialista anglosassone in cui l'abuso linguistico è parte formativa nella creazione di abitudini. "True stereo" segna un passaggio? No, è una sovrapposizione di stati. E "live electronics" segna un passaggio dal morto al vivo? No, purtroppo è una sovrapposizione di stati, dove "live", col tempo, verso oggi, ha sempre più segnato un punto di morte, intellettuale, piuttosto che contrassegnare una qualità. L'introduzione di nuove parole è sempre un atto di responsabilità, l'aggettivazione di una vecchia parola per creare un nuovo stato delle cose è sempre un atto di irresponsabilità.

Arrivo alla risposta: no, è un lavoro elettroacustico. Puro. Cage è tra i pionieri elettroacustici, almeno due decenni prima dei primi studi "elettronici" europei portava sul palco dispositivi elettroacustici. La musica è diventata elettroacustica prima che elettronica, ammesso che distinguere temporalmente su base tecnologica abbia un senso oltre quello del ragionamento tecnostorico. Tuttavia questo è vero solo se con queste parole vogliamo definire dei domini tecnologici discreti. Prima di lui, nei termini di una storia fatta di racconti di grandi accadimenti, a grana grossa, solo Respighi con i *Pini di Roma*. La prassi elettroacustica di Cage lo accompagnerà per molto tempo e con *Cartridge Music* si arriva al capolavoro intellettuale: lo classifico elettroacustico ma sottolineando la peculiare necessità teorico-pratica che solleva: scrittura, tecnologia, sono oggetti facili da manipolare, ma *Cartridge* lascia spazio al lavoro compositivo, interpretativo, cameristico, drammaturgico, azzarderei linguistico --- Mario Bertoncini riesce a farsene un dialetto!

#### Come è cambiato il tuo rapporto con il live electronics in funzione di questo brano?

È stato importantissimo: ho iniziato a disinteressarmene. Voglio essere chiaro su questo punto: da studente di Musica Elettronica ho utilizzato spesso "live electronics" per le mie pratiche musicali, perché è nel linguaggio "comune" del nostro ambito di intervento. Tuttavia, col tempo, me ne sono distaccato ed ho analizzato il fatto linguistico per orientare il mio disorientamento musicale. Non sono interessato al linguaggio che generalizza, ma a quello che puntualizza. Il mio lavoro, nel tempo, si è concentrato sulle qualità («che sono sempre quantità di quantità» --- Gramsci) dell'esperienza musicale. Cage l'ha divelta più volte perché io ho pensato di condividere con lui l'idea che la musica è solo viva. Se non è viva, se non c'è attività umana in atto, è altro dalla musica. Abbiamo altri nomi per le non-attività umane (sound-art, installazione... parole che funzionano benissimo e ci permettono di comprendere a cosa stiamo partecipando in quanto viventi! E ci sono gli ibridi tra queste parole, bellissimi territori liminali!) lascerei le parole antiche come Musica per quello che devono ancora dire, ammesso che chi le usi abbia ancora qualcosa da aggiungere. È una questione ontologica, la classificazione, la lista, è sempre una questione ontologica. Il discorso fondamentale per me è ridurre al minimo le sicurezze ontologiche: «questo è» può valere solo per poche cose e mai sovrapponibili. Per questo l'ibridazione tra classi ontologiche diverse, rigide, mi funziona bene, perché diventa un atto epistemologico. Ecco *Cartridge Music* secondo me, ben interpretato, porta a questo: che cos'è quello che sto facendo? È musica? Se sì perché? Se no è meglio che smetta! È suono o è rumore? Se non so rispondere a questa domanda è meglio che smetta! Questo per me è stato suonare *Cartridge Music*: interrogazioni continue che vivono oltre il tempo dell'atto musicale istantaneo, persistono molto tempo dopo l'aver titillato un oggetto inudibile reso udibile mediante catena elettroacustica. *Cartridge Music*, come *I'm Sitting in a Room* (Lucier), come *Thin*, per piatto sospeso e tam-tam (Branchi) sono lavori che consacrano la catena elettroacustica a strumento musicale e che hanno partecipato alla catalogazione, alla definizione delle cose.

#### Come è cambiato il rapporto con gli strumenti e la consapevolezza?

Cage, nel mio percorso, ha puntellato solo consapevolezze. Ho amato studiarlo, tanto, tuttavia meno che suonarlo. Adoro suonarlo. *Cartridge* è un momento di consapevolezza, per chiunque abbia desiderio di ascoltare. Tuttavia, ciò necessita un'attività complessa, non alla portata di tutti. Apparentemente tutti possono "fare" *Cartridge Music*, eppure, poi, analizzando l'artefatto, non tutti "hanno fatto" *Cartridge Music*. Quello che ho appena sentito, è stato *Cartridge Music*? Ecco *Cartridge* è un lavoro esclusivo. L'arte è esclusiva. Anche questa è una consapevolezza. Poca musica occidentale ha operato cambi di percezione del proprio rapporto con lo strumentario disponibile. Di questi pochissimi consentono la predisposizione di un proprio arsenale d'assedio alle roccaforti della musica occidentale stessa. Con arsenale mi riferisco agli oggetti da "sonare", al reperimento di vecchie cartucce o interfacce elettroacustiche sostitutive delle cartucce, senza dimenticare la distinzione epistemologica tra "object" e "environment" che già leggendo le istruzioni obbliga, di nuovo, a porsi delle domande: figura e sfondo sono elementi fondanti della composizione, non solo musicale. Infatti *Cartridge* non è solo musicabile.

#### Che relazioni hai trovato eseguendo Bertoncini il quale lo considerava "il prototipo di tutta la musica con elettronica dal vivo"?

Ho avuto modo di suonare *Cartridge* sotto la guida di Bertoncini, nella sua versione dialettale. Adoro i dialetti. Esigenze locali! *Societas*! Bertoncini ha assorbito Cage come ha assorbito Scarlatti in un modo particolare, esclusivo, verso il superlativo. Schiacciante. La sua musica è infinitamente più complessa e semplicemente più bella --- per dire una cosa musico-logica --- di quella di Cage. Perché Bertoncini, a differenza di Cage, aveva già la mulattiera battuta, quella che Thoreau aveva indicato, e Cage calpestato, Bertoncini la poteva correre. Relazioni: le relazioni che intuisco tra le mie due visioni dei due musicisti sono semplici: intelligenze fuori misura per i loro rispettivi campi fisici --- tempo e ambiente --- con cui approssimare al gioco, senza consumare, senza consumismo, senza turismo. La serietà di un sorriso è la loro più grande vicinanza. Emerge a ogni pagina dei loro scritti e, in Mario, anche in forma di dialetto musicale. Senti quanto è bello in italiano: musica con elettronica dal vivo. Senti quanto è bello quando le parole descrivono l'esperienza, l'attitudine, e non gli oggetti. È interessante la parola "prototipo" perché non parla tanto di *Cartridge* quanto della visione di Bertoncini: riconoscendo *Cartridge* come prototipo, Bertoncini ne rivela una costruzione, una complessità che lo stacca dal resto della musica elettroacustica coeva.

#### Se hai mai eseguito o studiato *Mikrophonie I*, ritieni che l'uso di filtri possa in qualche modo garantire a *Mikrophonie I* un primato come live electronics in confronto a *Cartridge Music*?

Per me i primati sono una specie animale. È un no. *Mikrophonie I* è un brano elettroacustico. Il nome è una tecnologia, minuta, del linguaggio. Scrivere "live electronics" di fianco a qualsiasi brano che abbia elettronica --- con natalità precedente all'introduzione industriale di "outboards" --- non aggiunge nulla alla musica, sottrae senso al lavoro umano. Equivale a pensare una corrispondenza tra Cage e Stockhausen fatta di sms ed e-mail --- riduzione della loro complessità di pensiero a categorie comunicative veloci. Ma quelle persone passavano molto più tempo di noi a pensarsi, che è un pensare reciprocamente, che è anche e soprattutto un pensare se stessi.

Non ho mai avuto il lusso di suonare *Mikrophonie I*, spero accada.

Tutto questo mi fa ricordare quella volta in cui Walter Branchi ci chiese: «perché Berio ha mai fatto musica elettronica?»

#### Nota

Con elettroacustico intendo un passaggio della musica dal solo dominio acustico ad un dominio elettro-acustico. Con dominio intendo sia campo che dominazione, l'uomo, dominando l'elettricità, ha dominato nuove dimensioni dell'essere uomo al mondo. L'elettronica è una fase dell'essere elettrico che ha sfumature tecnologiche, l'introduzione successiva di soluzioni evolute a problemi sollevati dal mondo elettrico. Voglio dire, quando si entra nella fase elettronica? Ciò ha portato un cambio radicale su scala planetaria? No, non come l'introduzione dell'elettricità. Sì ci sono stati salti, notevoli, miniaturizzazioni, soluzioni assurde! ma il passaggio da un dominio acustico a uno elettro-acustico non è stato risolto saltando in un altro dominio. Anche l'odierno uso di dispositivi a elaborazione numerica è inserito in una catena elettro-acustica. La chitarra elettrica è un salto dalla chitarra classica. Se poi la fanno anche elettronica non cambia più nulla --- sto dando per scontato che si consideri l'amplificazione parte dello strumento che chiamiamo Chitarra Elettrica. Elettroacustico per me è un dominio dell'essere. Elettronico è una delle classificazioni tecnologiche di quel dominio. L'oscillatore virtuale è più virtuale di un Beethoven sul divano di casa? «La parola è la cosa stessa, ma non è la stessa cosa». (Ferraris)


# BIBLIOGRAFIA

::: {#refs-bib}
:::

# SITOGRAFIA

::: {#refs-sit}
:::

